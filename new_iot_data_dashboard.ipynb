{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "# Run this with: \n",
    "#     voila --no-browser --VoilaConfiguration.file_whitelist=\"['.*.(nc|csv|.png)']\" --Voila.ip='0.0.0.0' --port=3600 iot_data_dashboard.ipynb\n",
    "#\n",
    "#     or\n",
    "#\n",
    "#     nohup voila --no-browser --VoilaConfiguration.file_whitelist=\"['.*.(nc|csv|.png)']\" --Voila.ip='0.0.0.0' --port=3600 iot_data_dashboard.ipynb >voila.out 2>&1 &\n",
    "#\n",
    "# Without whitelisting the logos in the 'about' tab won't appear, and the data file download  \n",
    "# will not work (error 403 'forbidden').\n",
    "# Note that within Jupyter notebook/lab only text file download will work (will be opened and\n",
    "# visualized in a new tab). But Jupyter doesn't know how to handle .nc files, and so gives you\n",
    "# a pop-up error with a silly message ('File download error: the file is not utf-8 encoded').\n",
    "# Download will work in voilà, provided that the files have been correctly whitelisted.\n",
    "# In the next cell the calls to 'display' may be commented out when working in Jupyter: they are\n",
    "# meant to avoid excessive whitespace on the page margins when running the dashboard in voilà.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, FileLink\n",
    "display(HTML(\"<style>.jp-Cell {padding: 0 !important; }</style>\"))\n",
    "display(HTML(\"<style>.jp-Notebook {padding: 0 !important; }</style>\"))\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil\n",
    "import base64\n",
    "from fnmatch import fnmatch\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant definitions\n",
    "\n",
    "MONGO_IP = '10.230.240.232'\n",
    "MONGO_PORT = 27017\n",
    "DATABASE = 'stations'\n",
    "\n",
    "DIRECTORY = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MongoDB\n",
    "client = pymongo.MongoClient(host=MONGO_IP, port=MONGO_PORT)\n",
    "db = client[DATABASE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataStore:\n",
    "#     \"\"\"\n",
    "#     This class queries the database and holds a pandas dataframe which stores all of the queried data\n",
    "#     It is also capable of outputting the data as a .csv or .nc file.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, db: pymongo.database.Database, station_num: int = 1):\n",
    "        \n",
    "#         self.db = db\n",
    "#         self.station_num = station_num\n",
    "\n",
    "#         # sets self.station to the appriopriate collection in the database\n",
    "#         self.station = db[f'station{station_num}']\n",
    "\n",
    "        \n",
    "#         # sets self.conf to the config document in the station collection\n",
    "#         self.conf = db['stations_info'].find_one({'config': True, 'station_num': station_num})\n",
    "        \n",
    "        \n",
    "#         # creates a list of the measurements to query for in the format sensor.measurement.index\n",
    "#         all_measurements = self.get_all_measurements()\n",
    "        \n",
    "#         # runs an aggregation pipeline to query for those measurements and then returns a pd dataframe\n",
    "#         self.data = self.query(all_measurements)\n",
    "        \n",
    "        \n",
    "#         self.datetime = self.data['datetime']\n",
    "\n",
    "#         self.measurements = self.get_measurement_names()\n",
    "        \n",
    "#         self.create_config()\n",
    "        \n",
    "#         # updates the files for the current months and all months since the last update\n",
    "#         self.update_files()\n",
    "\n",
    "#     def get_all_measurements(self):\n",
    "#         \"\"\"\n",
    "#         Queries the DB for graphable measurements and returns a list of strings in form sensor.measurement.index, i.e. particulate_matter.PM1count.1\n",
    "#         Excludes the gps data, and sensor, index, and type fields\n",
    "#         \"\"\"\n",
    "#         measurements = []\n",
    "        \n",
    "#         # chooses a non-config document\n",
    "#         doc = self.station.find_one({'config' : {\"$exists\" : False}})\n",
    "\n",
    "#         # iterates through each sensor in the document\n",
    "#         for sensor in doc:\n",
    "\n",
    "#             # excludes the object id field, datetime field, and gps sensor\n",
    "#             if sensor not in ['_id', 'datetime', 'gps']:\n",
    "#                 sensor_fields = doc[sensor]\n",
    "\n",
    "#                 # iterates through each field in the sensor, excluding the sensor name, index, and type/brand\n",
    "#                 for field in sensor_fields:\n",
    "#                     if field not in ['sensor', 'index', 'type']:\n",
    "\n",
    "#                         # adds each field to a list in form [particulate_matter.PM1count.0, air_sensor.humidity.1]\n",
    "#                         measurement = f\"{sensor_fields['sensor']}.{field}.{sensor_fields['index']}\" \n",
    "#                         measurements.append(measurement)\n",
    "\n",
    "#         return measurements \n",
    "\n",
    "#     def query(self, measurements: list):\n",
    "#         \"\"\"\n",
    "#         Runs an aggregation pipeline to query the database for the data given,\n",
    "#         then loads that data into a pandas dataframe\n",
    "        \n",
    "#         measurements: a list of measurements in the form sensor.measurement.index. \n",
    "#         can be generated by get_all_measurements()\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # includes only files which have a datetime field\n",
    "#         exclude_config = {'$match': {\n",
    "#             'datetime': {'$exists': True}\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         # sorts all documents by the datetime value, from earliest to latest\n",
    "#         sort_by_datetime = {'$sort': {\n",
    "#                 'datetime': 1\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         # unpacks the fields from the database format, i.e. \n",
    "#         # {\n",
    "#         # datetime: val\n",
    "#         # particulate_matter+0: {\n",
    "#         #     PM1count: val,\n",
    "#         #     PM1mass: val,\n",
    "#         #     }\n",
    "#         # air_sensor+1: {\n",
    "#         #     humidity: val,\n",
    "#         #     temperature: val\n",
    "#         #     }\n",
    "#         # }\n",
    "#         # becomes:\n",
    "#         # {\n",
    "#         # datetime: val\n",
    "#         # PM1count+0: val\n",
    "#         # PM1mass+0: val\n",
    "#         # humidity+1: val\n",
    "#         # temperature+1: val\n",
    "#         # }\n",
    "#         unpack = {'$project': {\n",
    "#                 '_id': 0, \n",
    "#                 'datetime': 1\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         # adds each measurement in the measurements parameter to the unpack stage\n",
    "#         for measurement in measurements:\n",
    "#             sensor, field, index = measurement.split(\".\")\n",
    "#             unpack['$project'][f'{field}+{index}'] = f'${sensor}+{index}.{field}'\n",
    "\n",
    "#         #runs the aggregation\n",
    "#         aggr = self.station.aggregate([exclude_config, sort_by_datetime, unpack], allowDiskUse = True)\n",
    "        \n",
    "#         #casts the aggregation as a list of dictionaries and then loads that list as a pandas dataframe\n",
    "#         df = pd.DataFrame(list(aggr))\n",
    "\n",
    "#         return df \n",
    "    \n",
    "#     def get_measurement_names(self):\n",
    "#         \"\"\"\n",
    "#         Returns a set of measurements in the form set('PM1count','PM1mass',...,'temperature','humidity','co2')\n",
    "#         Used for the button labels\n",
    "#         \"\"\"\n",
    "#         measurements = set()\n",
    "#         for key in self.data:\n",
    "#             if key != 'datetime':\n",
    "#                 measurements.add(f\"{key.split('+')[0]}\")\n",
    "\n",
    "#         return measurements\n",
    "\n",
    "#     def get_series(self, key: str):\n",
    "#         \"\"\"\n",
    "#         Returns the given series based on the name of its column. Identical to DataStore[column] or DataStore.data[column]\n",
    "#         \"\"\"\n",
    "#         return self.data[key]\n",
    "    \n",
    "#     def create_config(self):\n",
    "#         self.config = {}\n",
    "#         cols = self.data.columns\n",
    "        \n",
    "#         for col in cols:\n",
    "#             if col in self.measurements:\n",
    "#                 continue\n",
    "            \n",
    "#             measure = col.split('+')[0]\n",
    "#             self.config[measure] = self.config.get(measure, 0) + 1\n",
    "\n",
    "#     def to_csv(self, filename: str, start_date: str = None, end_date: str = None, cols: list = None):   \n",
    "#         \"\"\"\n",
    "#         Saves the dataframe as a .csv file\n",
    "        \n",
    "#         filename: The name of the file.\n",
    "#         start_date (Optional): The first day of values to include. Defaults to the first date in the dataframe\n",
    "#         end_date (Optional): The last day of values to include. Defaults to the last date in the dataframe\n",
    "#         cols (Optional): A list of columns to include in the file. Defaults to all columns.\n",
    "        \n",
    "#         to_csv(filename='january_data',start_date='2023-01',end_date='2023-01',cols=['tempeature+0',temperature+1'])\n",
    "#         will save january_data.csv, containing the temperature values from January 2023\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if start_date == None:\n",
    "#             start_date = self['datetime'].iloc[0]\n",
    "#         if end_date == None:\n",
    "#             end_date = self['datetime'].iloc[-1]\n",
    "            \n",
    "#         if cols == None:\n",
    "#             return self.data.set_index('datetime').loc[start_date:end_date,:].to_csv(f\"{filename}\", index=True, header=True)\n",
    "        \n",
    "#         return self.data.set_index('datetime').loc[start_date:end_date,cols].to_csv(f\"{filename}\", index=True, header=True)\n",
    "    \n",
    "#     def to_netcdf(self, filename: str, start_date: str = None, end_date: str = None, cols: list = None):\n",
    "#         \"\"\"\n",
    "#         Saves the dataframe as a .nc file\n",
    "        \n",
    "#         filename: The name of the file.\n",
    "#         start_date (Optional): The first day of values to include. Defaults to the first date in the dataframe\n",
    "#         end_date (Optional): The last day of values to include. Defaults to the last date in the dataframe\n",
    "#         cols (Optional): A list of columns to include in the file. Defaults to all columns.\n",
    "        \n",
    "#         to_nc(filename='january_data', start_date='2023-01', end_date='2023-01', cols=['tempeature+0',temperature+1'])\n",
    "#         will save january_data.nc, containing the temperature values from January 2023\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if start_date == None:\n",
    "#             start_date = self['datetime'].iloc[0]\n",
    "#         if end_date == None:\n",
    "#             end_date = self['datetime'].iloc[-1]\n",
    "            \n",
    "#         if cols == None:\n",
    "#             x = xr.Dataset.from_dataframe(self.data.set_index('datetime').loc[start_date:end_date,:])\n",
    "#         else:\n",
    "#             x = xr.Dataset.from_dataframe(self.data.set_index('datetime').loc[start_date:end_date,cols])\n",
    "            \n",
    "#         ### Per datum in the column, attributes need to be assigned, tentative list includes: full name, unit, sensor of origin, and various sensor specs\n",
    "            \n",
    "#         return x.to_netcdf(f\"{filename}\")\n",
    "        \n",
    "#     def __getitem__(self, key: str):\n",
    "#         return self.data[key]\n",
    "    \n",
    "#     def average_series(self, measurement: str):\n",
    "#         \"\"\"\n",
    "#         Given a measurement, returns a series with the average of all series' for that measurement.\n",
    "#         average_series('PM1count') will return the average of PM1count+0 and PM1count+1\n",
    "#         \"\"\"\n",
    "#         return pd.concat([self[x] for x in self.data if measurement in x], axis=1).agg(np.mean, 1)\n",
    "    \n",
    "#     def update_files(self):\n",
    "#         \"\"\"\n",
    "#         Updates all the files that need to be updated.\n",
    "#         References the database to determine the last time the files for the current station were updated\n",
    "#         Updates the file for the current month and all months between the current month and the last update\n",
    "        \n",
    "#         If there is no field in the reference document for the current station (i.e. if it is a new box), \n",
    "#         it creates/updates all the files for the station\n",
    "#         \"\"\"\n",
    "        \n",
    "#         #get current date\n",
    "#         today = datetime.today()\n",
    "\n",
    "#         #get list of months in the df\n",
    "#         months = self.data.set_index('datetime').index.to_period('m').unique().to_timestamp()\n",
    "        \n",
    "#         #check for the voila config file\n",
    "#         voila_config = self.db['stations_info'].find_one({'voila': True, f'station{self.station_num}': {'$exists' : True}})\n",
    "\n",
    "#         #if the station does not have a field in the config file, it creates it\n",
    "#         if voila_config == None:\n",
    "#             for date in months:\n",
    "#                 month = f'{date.year}-{date.month}'\n",
    "                \n",
    "#                 # reformats the name format if wrong\n",
    "#                 if len(month) < 7:\n",
    "#                     month = f'{date.year}-0{date.month}'\n",
    "\n",
    "#                 filename = f\"Station{self.station_num}_{month}.csv\"\n",
    "#                 self.to_csv(filename, month, month, None)\n",
    "\n",
    "#                 filename = f\"Station{self.station_num}_{month}.nc\"\n",
    "#                 self.to_netcdf(filename, month, month, None)\n",
    "        \n",
    "#         else:\n",
    "#             latest_update = voila_config[f'station{self.station_num}']\n",
    "            \n",
    "#             # creates an update a list of files to update, to avoid updating all the files every time the page is opened\n",
    "#             months_to_update = []\n",
    "\n",
    "#             for month in months:\n",
    "\n",
    "#                 if month >= latest_update:\n",
    "#                     months_to_update.append(month)\n",
    "\n",
    "#                 elif month.month == latest_update.month and month.year == latest_update.year:\n",
    "#                     months_to_update.append(month)\n",
    "\n",
    "#                 else:\n",
    "#                     pass\n",
    "            \n",
    "#             for date in months_to_update:\n",
    "#                 month = f'{date.year}-{date.month}'\n",
    "                \n",
    "#                 # reformat the name format if wrong\n",
    "#                 if len(month) < 7:\n",
    "#                     month = f'{date.year}-0{date.month}'\n",
    "\n",
    "#                 filename = f\"Station{self.station_num}_{month}.csv\"\n",
    "#                 self.to_csv(filename, month, month, None)\n",
    "\n",
    "#                 filename = f\"Station{self.station_num}_{month}.nc\"\n",
    "#                 self.to_netcdf(filename, month, month, None)\n",
    "        \n",
    "#         # updates the reference document in 'stations_info' to the current date \n",
    "#         self.db['stations_info'].update_one({'voila' : True}, {\"$set\" : {f'station{self.station_num}' : today}})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17877e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStore:\n",
    "    \"\"\"\n",
    "    This class queries the database and holds a pandas dataframe which stores all of the queried data\n",
    "    It is also capable of outputting the data as a .csv or .nc file.\n",
    "    \"\"\"\n",
    "    def __init__(self, db: pymongo.database.Database, station_num: int = 1):\n",
    "        \n",
    "        self.db = db\n",
    "        self.station_num = station_num\n",
    "\n",
    "        # sets self.station to the appriopriate collection in the database\n",
    "        self.station = db[f'station{station_num}']\n",
    "\n",
    "        \n",
    "        # sets self.conf to the config document in the station collection\n",
    "        self.conf = db['stations_info'].find_one({'config': True, 'station_num': station_num})\n",
    "        \n",
    "        \n",
    "        # creates a list of the measurements to query for in the format sensor.measurement.index\n",
    "        all_measurements = self.get_all_measurements()\n",
    "        \n",
    "        # runs an aggregation pipeline to query for those measurements and then returns a pd dataframe\n",
    "        self.data = self.query(all_measurements)\n",
    "        \n",
    "        \n",
    "        self.datetime = self.data['datetime']\n",
    "\n",
    "        self.measurements = self.get_measurement_names()\n",
    "        \n",
    "        self.create_config()\n",
    "        \n",
    "        # updates the files for the current months and all months since the last update\n",
    "        self.update_files()\n",
    "\n",
    "    def get_all_measurements(self):\n",
    "        \"\"\"\n",
    "        Queries the DB for graphable measurements and returns a list of strings in form sensor.measurement.index, i.e. particulate_matter.PM1count.1\n",
    "        Excludes the gps data, and sensor, index, and type fields\n",
    "        \"\"\"\n",
    "        measurements = []\n",
    "        \n",
    "        # chooses a non-config document\n",
    "        doc = self.station.find_one({'config' : {\"$exists\" : False}})\n",
    "\n",
    "        # iterates through each sensor in the document\n",
    "        for sensor in doc:\n",
    "\n",
    "            # excludes the object id field, datetime field, and gps sensor\n",
    "            if sensor not in ['_id', 'datetime', 'gps']:\n",
    "                sensor_fields = doc[sensor]\n",
    "\n",
    "                # iterates through each field in the sensor, excluding the sensor name, index, and type/brand\n",
    "                for field in sensor_fields:\n",
    "                    if field not in ['sensor', 'index', 'type']:\n",
    "\n",
    "                        # adds each field to a list in form [particulate_matter.PM1count.0, air_sensor.humidity.1]\n",
    "                        measurement = f\"{sensor_fields['sensor']}.{field}.{sensor_fields['index']}\" \n",
    "                        measurements.append(measurement)\n",
    "\n",
    "        return measurements \n",
    "\n",
    "    def query(self, measurements: list):\n",
    "        \"\"\"\n",
    "        Runs an aggregation pipeline to query the database for the data given,\n",
    "        then loads that data into a pandas dataframe\n",
    "        \n",
    "        measurements: a list of measurements in the form sensor.measurement.index. \n",
    "        can be generated by get_all_measurements()\n",
    "        \"\"\"\n",
    "        \n",
    "        # includes only files which have a datetime field\n",
    "        exclude_config = {'$match': {\n",
    "            'datetime': {'$exists': True}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # sorts all documents by the datetime value, from earliest to latest\n",
    "        sort_by_datetime = {'$sort': {\n",
    "                'datetime': 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # unpacks the fields from the database format, i.e. \n",
    "        # {\n",
    "        # datetime: val\n",
    "        # particulate_matter+0: {\n",
    "        #     PM1count: val,\n",
    "        #     PM1mass: val,\n",
    "        #     }\n",
    "        # air_sensor+1: {\n",
    "        #     humidity: val,\n",
    "        #     temperature: val\n",
    "        #     }\n",
    "        # }\n",
    "        # becomes:\n",
    "        # {\n",
    "        # datetime: val\n",
    "        # PM1count+0: val\n",
    "        # PM1mass+0: val\n",
    "        # humidity+1: val\n",
    "        # temperature+1: val\n",
    "        # }\n",
    "        unpack = {'$project': {\n",
    "                '_id': 0, \n",
    "                'datetime': 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # adds each measurement in the measurements parameter to the unpack stage\n",
    "        for measurement in measurements:\n",
    "            sensor, field, index = measurement.split(\".\")\n",
    "            unpack['$project'][f'{field}+{index}'] = f'${sensor}+{index}.{field}'\n",
    "\n",
    "        #runs the aggregation\n",
    "        aggr = self.station.aggregate([exclude_config, sort_by_datetime, unpack], allowDiskUse = True)\n",
    "        \n",
    "        #casts the aggregation as a list of dictionaries and then loads that list as a pandas dataframe\n",
    "        df = pd.DataFrame(list(aggr))\n",
    "\n",
    "        return df \n",
    "    \n",
    "    def get_measurement_names(self):\n",
    "        \"\"\"\n",
    "        Returns a set of measurements in the form set('PM1count','PM1mass',...,'temperature','humidity','co2')\n",
    "        Used for the button labels\n",
    "        \"\"\"\n",
    "        measurements = set()\n",
    "        for key in self.data:\n",
    "            if key != 'datetime':\n",
    "                measurements.add(f\"{key.split('+')[0]}\")\n",
    "\n",
    "        return measurements\n",
    "\n",
    "    def get_series(self, key: str):\n",
    "        \"\"\"\n",
    "        Returns the given series based on the name of its column. Identical to DataStore[column] or DataStore.data[column]\n",
    "        \"\"\"\n",
    "        return self.data[key]\n",
    "    \n",
    "    def create_config(self):\n",
    "        self.config = {}\n",
    "        cols = self.data.columns\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in self.measurements:\n",
    "                continue\n",
    "            \n",
    "            measure = col.split('+')[0]\n",
    "            self.config[measure] = self.config.get(measure, 0) + 1\n",
    "\n",
    "    def to_csv(self, filename: str, start_date: str = None, end_date: str = None, cols: list = None):   \n",
    "        \"\"\"\n",
    "        Saves the dataframe as a .csv file\n",
    "        \n",
    "        filename: The name of the file.\n",
    "        start_date (Optional): The first day of values to include. Defaults to the first date in the dataframe\n",
    "        end_date (Optional): The last day of values to include. Defaults to the last date in the dataframe\n",
    "        cols (Optional): A list of columns to include in the file. Defaults to all columns.\n",
    "        \n",
    "        to_csv(filename='january_data',start_date='2023-01',end_date='2023-01',cols=['tempeature+0',temperature+1'])\n",
    "        will save january_data.csv, containing the temperature values from January 2023\n",
    "        \"\"\"\n",
    "        \n",
    "        if start_date == None:\n",
    "            start_date = self['datetime'].iloc[0]\n",
    "        if end_date == None:\n",
    "            end_date = self['datetime'].iloc[-1]\n",
    "            \n",
    "        if cols == None:\n",
    "            return self.data.set_index('datetime').loc[start_date:end_date,:].to_csv(f\"{filename}\", index=True, header=True)\n",
    "        \n",
    "        return self.data.set_index('datetime').loc[start_date:end_date,cols].to_csv(f\"{filename}\", index=True, header=True)\n",
    "    \n",
    "    def to_netcdf(self, filename: str, start_date: str = None, end_date: str = None, cols: list = None):\n",
    "        \"\"\"\n",
    "        Saves the dataframe as a .nc file\n",
    "        \n",
    "        filename: The name of the file.\n",
    "        start_date (Optional): The first day of values to include. Defaults to the first date in the dataframe\n",
    "        end_date (Optional): The last day of values to include. Defaults to the last date in the dataframe\n",
    "        cols (Optional): A list of columns to include in the file. Defaults to all columns.\n",
    "        \n",
    "        to_nc(filename='january_data', start_date='2023-01', end_date='2023-01', cols=['tempeature+0',temperature+1'])\n",
    "        will save january_data.nc, containing the temperature values from January 2023\n",
    "        \"\"\"\n",
    "        \n",
    "        if start_date == None:\n",
    "            start_date = self['datetime'].iloc[0]\n",
    "        if end_date == None:\n",
    "            end_date = self['datetime'].iloc[-1]\n",
    "            \n",
    "        if cols == None:\n",
    "            x = xr.Dataset.from_dataframe(self.data.set_index('datetime').loc[start_date:end_date,:])\n",
    "        else:\n",
    "            x = xr.Dataset.from_dataframe(self.data.set_index('datetime').loc[start_date:end_date,cols])\n",
    "            \n",
    "        ### Per datum in the column, attributes need to be assigned, tentative list includes: full name, unit, sensor of origin, and various sensor specs\n",
    "            \n",
    "        return x.to_netcdf(f\"{filename}\")\n",
    "        \n",
    "    def __getitem__(self, key: str):\n",
    "        return self.data[key]\n",
    "    \n",
    "    def average_series(self, measurement: str):\n",
    "        \"\"\"\n",
    "        Given a measurement, returns a series with the average of all series' for that measurement.\n",
    "        average_series('PM1count') will return the average of PM1count+0 and PM1count+1\n",
    "        \"\"\"\n",
    "        return pd.concat([self[x] for x in self.data if measurement in x], axis=1).agg(np.mean, 1)\n",
    "\n",
    "    def update_files(self):\n",
    "        \"\"\"\n",
    "        Updates all the files that need to be updated.\n",
    "        Identifies missing or incomplete data files and generates them.\n",
    "        \"\"\"\n",
    "        # Get current date\n",
    "        today = datetime.today()\n",
    "\n",
    "        # Get the list of months represented in the dataframe\n",
    "        months = self.data.set_index('datetime').index.to_period('m').unique()\n",
    "\n",
    "        # Retrieve the last update date from the database\n",
    "        voila_config = self.db['stations_info'].find_one({'voila': True})\n",
    "        last_update = voila_config.get(f'station{self.station_num}', datetime.min)\n",
    "\n",
    "        # Generate file for each month if it's after the last update or if it's the current month\n",
    "        for month_period in months:\n",
    "            month_start = month_period.start_time\n",
    "            month_end = month_period.end_time\n",
    "\n",
    "            # Check if the month is after the last update or if it's the current month\n",
    "            if month_start > last_update or month_start.month == today.month and month_start.year == today.year:\n",
    "                filename_prefix = f\"Station{self.station_num}_{month_start.strftime('%Y-%m')}\"\n",
    "\n",
    "                # Save as CSV\n",
    "                self.to_csv(f\"{filename_prefix}.csv\", month_start, month_end)\n",
    "\n",
    "                # Save as NetCDF\n",
    "                self.to_netcdf(f\"{filename_prefix}.nc\", month_start, month_end)\n",
    "\n",
    "        # Update the last update date in the database\n",
    "        self.db['stations_info'].update_one({'voila': True}, {\"$set\": {f'station{self.station_num}': today}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    '''\n",
    "    Class to manage everything to do with plotting and plt\n",
    "    '''\n",
    "    \n",
    "    DEFAULT_COLORS = {0: ['#8B0000', '#FF3131'],\n",
    "                      1: ['#00008B', '#1F51FF'],\n",
    "                      2: ['#008B00', '#39FF14'],\n",
    "                      3: ['#8B8000', '#FFFF33']}\n",
    "    \n",
    "    def __init__(self, x_axis: iter, date_range_slider: widgets.SelectionRangeSlider) -> None:\n",
    "        '''\n",
    "        Initializes class\n",
    "        @param x-axis Iterable containing x-axis elements. All plots managed by this plotter class must share\n",
    "            the same x-axis\n",
    "        @param date_range_slider Slider widget to control / limit the range of the x-axis\n",
    "        '''\n",
    "        \n",
    "        # set up figure and plt settings\n",
    "        plt.ioff()\n",
    "        self.fig = plt.figure()\n",
    "        self.fig.canvas.header_visible = False\n",
    "        self.fig.canvas.resizable = False\n",
    "        self.fig.canvas.toolbar_position = 'right'\n",
    "        self.fig.canvas.layout.width = '100%'\n",
    "        self.fig.set_figwidth(7)\n",
    "        \n",
    "        self.date_range_slider = date_range_slider\n",
    "        \n",
    "        # initialize variables\n",
    "        self.x_axis = np.array(x_axis)\n",
    "        self.axes = []\n",
    "        self.colors = list(self.DEFAULT_COLORS.keys())  # keeps track of int for each default color\n",
    "        self.max_graphs = len(self.colors)\n",
    "        self.curr_graphs = 0\n",
    "\n",
    "\n",
    "    def add_plot(self, data: iter, description: str) -> plt.Axes:\n",
    "        '''\n",
    "        Create a new subplot for the graph\n",
    "        @param data Iterable of y-data to plot, len(data) must match len(self.x_axis)\n",
    "        @param description What is being plotted, label for y-axis\n",
    "        '''\n",
    "        \n",
    "        # check if we can add new plot\n",
    "        # checks if data is compatible\n",
    "        if (self.curr_graphs >= self.max_graphs) or \\\n",
    "            (data is None) or \\\n",
    "            (len(self.x_axis) != len(data)):\n",
    "            return None\n",
    "        \n",
    "        if self.curr_graphs == 0:\n",
    "            ax = self.fig.add_subplot()\n",
    "        else:\n",
    "            ax = self.axes[0].twinx()\n",
    "            # pushes axis further away to not overlap\n",
    "            ax.spines['right'].set_position(('outward', \n",
    "                                             50*(self.curr_graphs - 1)))\n",
    "        \n",
    "        # add graph description\n",
    "        ax.description = description\n",
    "        \n",
    "        # plot\n",
    "        ax.color = self.colors.pop()\n",
    "        g_color = self.DEFAULT_COLORS[ax.color][0]  # new plots use the first color, subplots the second\n",
    "        ax.plot(self.x_axis, data, '.',\n",
    "               markersize=1, color=g_color)\n",
    "        \n",
    "        # edit axis info\n",
    "        ax.set_ylabel(description, \n",
    "                        fontsize=12, color=g_color)\n",
    "        ax.tick_params(axis='y', colors=g_color)\n",
    "        self.fig.autofmt_xdate(rotation=45)\n",
    "        \n",
    "        \n",
    "        self.curr_graphs += 1\n",
    "        self.axes.append(ax)\n",
    "        self.date_range_callback({'name': 'value'})\n",
    "        return ax\n",
    "\n",
    "\n",
    "    def add_subplot(self, data: iter, ax: plt.Axes) -> None:\n",
    "        '''\n",
    "        Adds new plot to an existing axis\n",
    "        Only supports adding a single subplot per axes\n",
    "        @param data Iterable of data to plot\n",
    "        @param ax Existing plt.Axes object to graph\n",
    "        '''\n",
    "        g_color = self.DEFAULT_COLORS[ax.color][1]\n",
    "        ax.plot(self.x_axis, data, '.', markersize=1, color=g_color)\n",
    "        self.date_range_callback({'name': 'value'})\n",
    "\n",
    "\n",
    "    def clear_plots(self) -> None:\n",
    "        '''\n",
    "        Clears all the plots and axes\n",
    "        Resets the figure and list of available colors\n",
    "        '''\n",
    "        self.fig.clf()\n",
    "        self.axes = []\n",
    "        self.colors = list(self.DEFAULT_COLORS.keys())\n",
    "        self.curr_graphs = 0\n",
    "        #self.date_range_callback({'name': 'value'})\n",
    "    \n",
    "    \n",
    "    def date_range_callback(self, wdic: dict) -> None:\n",
    "        '''\n",
    "        Callback for date range slider to edid min/max dates on graph\n",
    "        '''\n",
    "        \n",
    "        if wdic['name'] != 'value':\n",
    "            return\n",
    "        #The right end of the date range needs to be rounded up to the next day\n",
    "        min_day = self.date_range_slider.value[0]\n",
    "        max_day = self.date_range_slider.value[1] + timedelta(days=1)\n",
    "        try:\n",
    "            self.axes[0].set_xlim((min_day, max_day))\n",
    "        finally:\n",
    "            self.finish_callback()\n",
    "    \n",
    "    \n",
    "    def finish_callback(self):\n",
    "        self.fig.tight_layout(pad=1.02)\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.canvas.flush_events()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07465fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ButtonList:\n",
    "    '''\n",
    "    This class groups all the buttons for different measurements of a sensor\n",
    "    Manages the button callback functions and sending the appropriate info to the plotter object\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data: DataStore, plotter: Plotter) -> None:\n",
    "        '''\n",
    "        Creates a new instance of a ButtonList\n",
    "        @param data Instance of DataStore class. Contains the data to plot and also the attributes to \n",
    "            generate the buttons\n",
    "        @param plotter Instance of Plotter class, manages the plotting of items\n",
    "        '''\n",
    "        \n",
    "        # initiate class variables\n",
    "        self.store = data\n",
    "        self.plotter = plotter\n",
    "        \n",
    "        # collect info from DataStore object\n",
    "        self.timeseries = self.store.datetime\n",
    "        self.measurements = list(self.store.measurements)\n",
    "        \n",
    "        # init all buttons\n",
    "        self.button_list = []\n",
    "        self.active_buttons = []  # keeps track of currently active buttons\n",
    "        for measurement in sorted(self.measurements):\n",
    "            \n",
    "\n",
    "            self.button_list.append(\n",
    "                widgets.ToggleButton(\n",
    "                    value = False,\n",
    "                    description = measurement,\n",
    "                    tooltip = measurement,\n",
    "                    # tooltip=f\"{self.store.data[ts][self.store.iLONG_NAME]} ({self.store.data[ts][self.store.iUNITS]})\",\n",
    "                    disabled=False,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # add the callback function to the button\n",
    "            self.button_list[-1].observe(self.callback)\n",
    "            \n",
    "            # button_list[-1]._Fidas_dashboard_units = self.store.data[ts][self.store.iUNITS]\n",
    "\n",
    "        self.buttons = widgets.VBox(self.button_list)\n",
    "\n",
    "        \n",
    "    def callback(self, wdic: dict) -> None:\n",
    "        '''\n",
    "        Gets called when a button gets clicked\n",
    "        Plots / clears the clicked button's measurments\n",
    "        @param wdic Dictionary passed by the button. Contains at least the following keys:\n",
    "            'type': type of notification\n",
    "            If wdic['type'] is 'change' then the following keys are also passed\n",
    "            'owner': the HasTraits instance\n",
    "            'old': old value of the modified trait\n",
    "            'new': new value of modified trait attribute\n",
    "            'name': name of modified trait attribute\n",
    "        '''\n",
    "        \n",
    "        # check if the trait changed is 'value'\n",
    "        if wdic['name'] != 'value':\n",
    "            return\n",
    "        \n",
    "        # check if data is being de-selected\n",
    "        elif wdic['new'] == False:\n",
    "\n",
    "            # remove element from the list of active buttons\n",
    "            if wdic['owner'] in self.active_buttons:\n",
    "                self.active_buttons.remove(wdic['owner'])\n",
    "                \n",
    "            else:\n",
    "                return\n",
    "\n",
    "            # clear plotter\n",
    "            self.plotter.clear_plots()\n",
    "            self.plot_graphs()  # plots all active buttons\n",
    "            return\n",
    "        \n",
    "        # try and plot graph\n",
    "        if not self.plot_graph(wdic['owner']):\n",
    "            wdic['owner'].value = False  # change the value back to false if unable to plot it\n",
    "        else:\n",
    "            self.active_buttons.append(wdic['owner'])\n",
    "\n",
    "\n",
    "    def plot_graphs(self) -> None:\n",
    "        '''\n",
    "        Plots all graphs in self.active_buttons\n",
    "        '''\n",
    "        for button in self.active_buttons:\n",
    "            self.plot_graph(button)\n",
    "\n",
    "\n",
    "    def plot_graph(self, button: widgets.ToggleButton) -> bool:\n",
    "        '''\n",
    "        Plots the data of the specified @param button\n",
    "        If unable to plot it, returns False\n",
    "        '''\n",
    "        \n",
    "        # get the attribute being plotted\n",
    "        description = button.description\n",
    "        \n",
    "        # first collect the number of plots (1 or 2)\n",
    "        num_plots = self.store.config.get(description, 0)\n",
    "        \n",
    "        # try plotting the first graph\n",
    "        if num_plots == 0:\n",
    "            # key isn't found in cofig\n",
    "            ax = self.plotter.add_plot(self.store.data[description], description)\n",
    "        else:\n",
    "            # key is found in config\n",
    "            ax = self.plotter.add_plot(self.store.average_series(description), description)\n",
    "            #ax = self.plotter.add_plot(self.store.data[f'{description}+0'], description)\n",
    "            \n",
    "            \n",
    "        if ax is None:\n",
    "            return False\n",
    "        \n",
    "        # try plotting subplot if needed\n",
    "#         if num_plots == 2:\n",
    "#             self.plotter.add_subplot(self.store.data[f'{description}+1'], ax)\n",
    "        \n",
    "        return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ad45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------\n",
    "#***Widgets for the intro/about tab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = []\n",
    "\n",
    "intro = widgets.HTML(\n",
    "    value=\"\"\"<p style=\"line-height: 150%\">The Arabian Center for Climate and Environmental Sciences is currently\n",
    "    hosting multiple environmental sensors at NYUAD, collecting particulate matter, temperature, pressure, and\n",
    "    weather data. Using the tabs above, you can visualize data from these sensors. </p>\n",
    "    <p>&nbsp;</p>\"\"\",\n",
    "    layout=widgets.Layout(width='700px')\n",
    ")\n",
    "logo_ACCESS = widgets.HTML(\n",
    "    value='<img src=\"ACCESS.png\" alt=\"Arabian Center for Climate and Environmental Sciences\" style=\"width:300px\">',\n",
    "    layout=widgets.Layout(\n",
    "        margin='0 20px 0 20px'\n",
    "    )\n",
    ")\n",
    "\n",
    "tab_about = widgets.VBox([intro, widgets.HBox([logo_ACCESS])])\n",
    "\n",
    "tabs.append(tab_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4374a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Widgets for the station time series tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db['stations_info'].find({'config' : True}):\n",
    "    if doc['station_num'] != 0:\n",
    "        data = DataStore(db,doc['station_num'])\n",
    "        slider_days = np.unique([x.date() for x in data.datetime])\n",
    "        date_range_slider = widgets.SelectionRangeSlider(\n",
    "            options = slider_days,\n",
    "            description = 'Date range:',\n",
    "            orientation = 'horizontal',\n",
    "            index = (0, len(slider_days)-1),\n",
    "            disabled = False,\n",
    "            continuous_update = False,\n",
    "            tooltip = 'Select the date range to be plotted',\n",
    "            layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        plotter = Plotter(data.datetime, date_range_slider)\n",
    "\n",
    "        date_range_slider.observe(plotter.date_range_callback)\n",
    "\n",
    "        button_list = ButtonList(data, plotter)\n",
    "        \n",
    "        decorated_canvas = widgets.VBox([date_range_slider,\n",
    "                                 plotter.fig.canvas])\n",
    "        tab_time_series = widgets.HBox([button_list.buttons, decorated_canvas])\n",
    "        tabs.append(tab_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b15fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------\n",
    "#Widgets for the download tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = '.'\n",
    "\n",
    "files = os.listdir(DIRECTORY)\n",
    "grouped_files = {}\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".csv\") or file.endswith(\".nc\"):\n",
    "        station, file_type = file.split(\"_\")[0].split(\".\")[0], file.split(\".\")[1]\n",
    "        if station not in grouped_files:\n",
    "            grouped_files[station] = {'csv':[],'nc':[]}\n",
    "        grouped_files[station][file_type].append(file)\n",
    "\n",
    "grouped_files = dict(sorted(grouped_files.items()))\n",
    "vboxes = []\n",
    "\n",
    "for station in grouped_files:\n",
    "    csvs = [\n",
    "    widgets.HTML(\n",
    "        value='<u style=\"color:blue;\">'+FileLink(f'{x}')._repr_html_()+'</u>',\n",
    "        placeholder='',\n",
    "        description='',\n",
    "        tooltip='Click the link to download the file'\n",
    "    ) for x in sorted(grouped_files[station]['csv'], key=lambda name: name[-11:-7]+name[-6:-4])\n",
    "    ]\n",
    "    ncs = [\n",
    "    widgets.HTML(\n",
    "        value='<u style=\"color:blue;\">'+FileLink(f'{x}')._repr_html_()+'</u>',\n",
    "        placeholder='',\n",
    "        description='',\n",
    "        tooltip='Click the link to download the file'\n",
    "    ) for x in sorted(grouped_files[station]['nc'], key=lambda name: name[-10:-6]+name[-5:-3])\n",
    "    ]\n",
    "    hbox = widgets.HBox([widgets.VBox(csvs, layout=widgets.Layout(margin='0 20px 0 0')),\n",
    "                         widgets.VBox(ncs, layout=widgets.Layout(margin='0 20px 0 0'))])\n",
    "    label = widgets.HTML(\n",
    "         value=f\"<b>{station[0:7]} {station.replace('Station','')} Data</b><br>\"\n",
    "     )\n",
    "    vbox = widgets.VBox([label, hbox],layout=widgets.Layout(margin='0 50px 0 0'))\n",
    "    \n",
    "    vboxes.append(vbox)\n",
    "\n",
    "tab_downloads = widgets.HBox(vboxes)\n",
    "tabs.append(tab_downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------\n",
    "#***Display the tabbed interface***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a44b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create widget\n",
    "tabbed_interface = widgets.Tab()\n",
    "\n",
    "# set the tabs as tabs list\n",
    "tabbed_interface.children = tabs\n",
    "\n",
    "# set the title of the first tab as the About page\n",
    "tabbed_interface.set_title(0, 'About')\n",
    "\n",
    "# set the title of each time series tab to the correct station number\n",
    "for doc in db['stations_info'].find({'config' : True}):\n",
    "    station_num = doc['station_num']\n",
    "    if station_num != 0:\n",
    "        tabbed_interface.set_title(station_num, f'Sensor {station_num} time series')\n",
    "        \n",
    "# set the title of the download tab\n",
    "tabbed_interface.set_title(station_num+1, 'Data download')\n",
    "\n",
    "display(tabbed_interface)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
